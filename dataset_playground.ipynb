{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Mixing Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sayed.mansouri-tehrani/.conda/envs/bb/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "# use hydra configs to load the dataset\n",
    "import hydra\n",
    "from utils import hydra_custom_resolvers\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "configs_path = \"configs\"\n",
    "# config_name = \"train_root.yaml\"\n",
    "config_name = \"train_root.yaml\"\n",
    "\n",
    "with hydra.initialize(config_path=configs_path):\n",
    "    config = hydra.compose(config_name=config_name,\n",
    "                            overrides=[\n",
    "                                \"datamodule=mixing\",\n",
    "                                \"datamodule.dataset.num_domains=10\",\n",
    "                                # \"model=mixing\"\n",
    "                            ],\n",
    "                            return_hydra_config=True,\n",
    "    )\n",
    "\n",
    "    # setup the dataset with the hydra config\n",
    "    datamodule = hydra.utils.instantiate(config.datamodule, _recursive_=False)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    # instantiate the model with hydra\n",
    "    # model = hydra.utils.instantiate(config.model, _recursive_=False)\n",
    "\n",
    "iterator = iter(datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim_invariant_data = datamodule.train_dataset.dataset.z_dim_invariant\n",
    "z_dim = datamodule.train_dataset.dataset.z_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0984)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), :z_dim_invariant_data].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "domain:0, z_dim:2 -- min:-3.395689010620117, max:-1.9791346788406372, mean:-2.710878849029541\n",
      "domain:0, z_dim:3 -- min:-1.2148573398590088, max:-0.8057138919830322, mean:-1.0142569541931152\n",
      "domain:1, z_dim:2 -- min:-4.767006874084473, max:-2.539933681488037, mean:-3.676292896270752\n",
      "domain:1, z_dim:3 -- min:-4.0764007568359375, max:-0.9848365783691406, mean:-2.4427056312561035\n",
      "domain:2, z_dim:2 -- min:-1.7045924663543701, max:-0.3207516670227051, mean:-0.9372190237045288\n",
      "domain:2, z_dim:3 -- min:1.9994860887527466, max:2.109677791595459, mean:2.0614607334136963\n",
      "domain:3, z_dim:2 -- min:3.3331382274627686, max:4.46589469909668, mean:3.8830065727233887\n",
      "domain:3, z_dim:3 -- min:-2.0340495109558105, max:-0.48385369777679443, mean:-1.1251734495162964\n",
      "domain:4, z_dim:2 -- min:-2.998680353164673, max:-1.8430469036102295, mean:-2.490309715270996\n",
      "domain:4, z_dim:3 -- min:-4.002238750457764, max:-3.2039177417755127, mean:-3.526283025741577\n",
      "domain:5, z_dim:2 -- min:-4.054628849029541, max:-0.6411967277526855, mean:-2.3517112731933594\n",
      "domain:5, z_dim:3 -- min:3.238177537918091, max:4.8626790046691895, mean:4.02437162399292\n",
      "domain:6, z_dim:2 -- min:3.003408670425415, max:3.540334701538086, mean:3.2923946380615234\n",
      "domain:6, z_dim:3 -- min:-2.2823867797851562, max:-1.5723302364349365, mean:-1.9512783288955688\n",
      "domain:7, z_dim:2 -- min:2.2318673133850098, max:3.1999824047088623, mean:2.687049627304077\n",
      "domain:7, z_dim:3 -- min:1.573473334312439, max:2.007068395614624, mean:1.7897320985794067\n",
      "domain:8, z_dim:2 -- min:1.8634604215621948, max:2.204680919647217, mean:2.049686908721924\n",
      "domain:8, z_dim:3 -- min:-3.5353214740753174, max:-0.9030609130859375, mean:-2.120600938796997\n",
      "domain:9, z_dim:2 -- min:-4.245664596557617, max:-1.352147102355957, mean:-2.533360242843628\n",
      "domain:9, z_dim:3 -- min:-2.720309257507324, max:-2.100924253463745, mean:-2.4299817085266113\n"
     ]
    }
   ],
   "source": [
    "for domain_idx in range(datamodule.train_dataset.dataset.num_domains):\n",
    "    print(f\"domain:{domain_idx} -- min:{batch['z'][(batch['domain'] == domain_idx).squeeze(), :z_dim_invariant_data].min()}, max:{batch['z'][(batch['domain'] == domain_idx).squeeze(), :z_dim_invariant_data].max()}, mean:{batch['z'][(batch['domain'] == domain_idx).squeeze(), :z_dim_invariant_data].mean()}\")\n",
    "print(\"----------------\")\n",
    "for domain_idx in range(datamodule.train_dataset.dataset.num_domains):\n",
    "    print(f\"domain:{domain_idx} -- min:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_invariant_data:].min()}, max:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_invariant_data:].max()}, mean:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_invariant_data:].mean()}\")\n",
    "print(\"----------------\")\n",
    "for domain_idx in range(datamodule.train_dataset.dataset.num_domains):\n",
    "    for z_dim_spurious in range(z_dim_invariant_data, z_dim):\n",
    "        print(f\"domain:{domain_idx}, z_dim:{z_dim_spurious} -- min:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_spurious].min()}, max:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_spurious].max()}, mean:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_spurious].mean()}\")\n",
    "\n",
    "\n",
    "# # print(batch[\"z\"][(batch[\"domain\"] == 0).squeeze(), z_dim_invariant_data:].min())\n",
    "\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), :z_dim_invariant_data].min())\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), z_dim_invariant_data:].min())\n",
    "\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 0).squeeze(), :z_dim_invariant_data].max())\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 0).squeeze(), z_dim_invariant_data:].max())\n",
    "\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), :z_dim_invariant_data].max())\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), z_dim_invariant_data:].max())\n",
    "\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 0).squeeze(), :z_dim_invariant_data].mean())\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 0).squeeze(), z_dim_invariant_data:].mean())\n",
    "\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), :z_dim_invariant_data].mean())\n",
    "# print(batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), z_dim_invariant_data:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0189)\n",
      "tensor(1.6085)\n",
      "tensor(3.2615)\n",
      "tensor(2.8083)\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"x\"][(batch[\"domain\"] == 0).squeeze(), :5].min())\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 0).squeeze(), 5:].min())\n",
    "\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 1).squeeze(), :5].min())\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 1).squeeze(), 5:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.8686)\n",
      "tensor(8.8918)\n",
      "tensor(10.6636)\n",
      "tensor(11.8312)\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"x\"][(batch[\"domain\"] == 0).squeeze(), :5].max())\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 0).squeeze(), 5:].max())\n",
    "\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 1).squeeze(), :5].max())\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 1).squeeze(), 5:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5176)\n",
      "tensor(5.1726)\n",
      "tensor(6.8904)\n",
      "tensor(7.8361)\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"x\"][(batch[\"domain\"] == 0).squeeze(), :5].mean())\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 0).squeeze(), 5:].mean())\n",
    "\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 1).squeeze(), :5].mean())\n",
    "print(batch[\"x\"][(batch[\"domain\"] == 1).squeeze(), 5:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coloured MNIST Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golden standard\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "# laod MNIST\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "root = \"/network/datasets/torchvision\"\n",
    "data = torchvision.datasets.MNIST(root, True, transform=transform)\n",
    "\n",
    "# color it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].permute(1,2,0).repeat(1, 1, 3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sayed.mansouri-tehrani/.conda/envs/bb/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "# use hydra configs to load the dataset\n",
    "import hydra\n",
    "from utils import hydra_custom_resolvers\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "configs_path = \"configs\"\n",
    "# config_name = \"train_root.yaml\"\n",
    "config_name = \"evaluate_root.yaml\"\n",
    "\n",
    "with hydra.initialize(config_path=configs_path):\n",
    "    config = hydra.compose(config_name=config_name,\n",
    "                            overrides=[\n",
    "                                \"datamodule/dataset=mnist\",\n",
    "                                # \"datamodule/dataset=multi_domain_mnist\",\n",
    "                                \"+ckpt_path='/home/mila/s/sayed.mansouri-tehrani/MD-CRL/autoencoder_multi_domain_mnist_32-epoch=52-val_loss=0.01.ckpt'\",\n",
    "                                \"model.autoencoder.num_channels=3\",\n",
    "                            ],\n",
    "                            return_hydra_config=True,\n",
    "    )\n",
    "\n",
    "    transform = transforms.Compose([hydra.utils.instantiate(t) for _, t in config.datamodule.transforms.items()])\n",
    "    def renormalize():\n",
    "        for _, t in config.datamodule.transforms.items():\n",
    "            if \"Standardize\" in t[\"_target_\"]:\n",
    "                \"\"\"Renormalize from [-1, 1] to [0, 1].\"\"\"\n",
    "                return lambda x: x / 2.0 + 0.5\n",
    "            \n",
    "    # setup the dataset with the hydra config\n",
    "    datamodule = hydra.utils.instantiate(config.datamodule, _recursive_=False)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    # instantiate the model with hydra\n",
    "    # model = hydra.utils.instantiate(config.model, _recursive_=False)\n",
    "\n",
    "renormalize = datamodule.renormalize()\n",
    "iterator = iter(datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load(\"/home/mila/s/sayed.mansouri-tehrani/MD-CRL/autoencoder_multi_domain_mnist_32-epoch=52-val_loss=0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in model.state_dict().keys():\n",
    "    print((model.state_dict()[key] == m[\"state_dict\"][key].to('cpu')).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"decoder_fc\":   {'_target_': 'models.modules.fc_ae.Decoder', 'latent_size': 32, 'width': 28, 'height': 28, 'num_channels': 3, 'decoder_layers': {'Linear1': {'_target_': 'torch.nn.Linear', 'in_features': 32, 'out_features': 64}, 'LeakyReLU1': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout1': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear2': {'_target_': 'torch.nn.Linear', 'in_features': 64, 'out_features': 128}, 'LeakyReLU2': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout2': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear3': {'_target_': 'torch.nn.Linear', 'in_features': 128, 'out_features': 256}, 'LeakyReLU3': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout3': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear4': {'_target_': 'torch.nn.Linear', 'in_features': 256, 'out_features': 512}, 'LeakyReLU4': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout4': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear5': {'_target_': 'torch.nn.Linear', 'in_features': 512, 'out_features': 2352}, 'LeakyReLU5': {'_target_': 'torch.nn.LeakyReLU'}}}\n",
       "\"encoder_fc\":   {'_target_': 'models.modules.fc_ae.Encoder', 'latent_size': 32, 'width': 28, 'height': 28, 'encoder_layers': {'Flatten': {'_target_': 'torch.nn.Flatten'}, 'Linear1': {'_target_': 'torch.nn.Linear', 'in_features': 2352, 'out_features': 512}, 'LeakyReLU1': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout1': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear2': {'_target_': 'torch.nn.Linear', 'in_features': 512, 'out_features': 256}, 'LeakyReLU2': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout2': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear3': {'_target_': 'torch.nn.Linear', 'in_features': 256, 'out_features': 128}, 'LeakyReLU3': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout3': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear4': {'_target_': 'torch.nn.Linear', 'in_features': 128, 'out_features': 64}, 'LeakyReLU4': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout4': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear5': {'_target_': 'torch.nn.Linear', 'in_features': 64, 'out_features': 32}, 'LeakyReLU5': {'_target_': 'torch.nn.LeakyReLU'}}}\n",
       "\"height\":       28\n",
       "\"latent_dim\":   32\n",
       "\"num_channels\": 3\n",
       "\"width\":        28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator)\n",
    "img, labels = batch[\"image\"], batch[\"label\"]\n",
    "# img, labels, domains, colors = batch[\"image\"], batch[\"label\"], batch[\"domain\"], batch[\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, recons = model.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_z_mins = torch.zeros((2, 16, 5))\n",
    "domain_z_maxs = torch.zeros((2, 16, 5))\n",
    "\n",
    "# z is [batch_size, latent_dim], so is domains. For the first d dimensions\n",
    "# of z, find the top_k smallest values of that dimension in each domain\n",
    "# find the mask of z's for each domain\n",
    "# for each domain, and for each of the first d dimensions, \n",
    "# find the top_k smallest values of that z dimension in that domain\n",
    "for domain_idx in range(2):\n",
    "    domain_mask = (domains == domain_idx).squeeze()\n",
    "    domain_z = z[domain_mask]\n",
    "    # for each dimension i among the first d dimensions of z, find the top_k\n",
    "    # smallest values of dimension i in domain_z\n",
    "    for i in range(16):\n",
    "        domain_z_sorted, _ = torch.sort(domain_z[:, i], dim=0)\n",
    "        domain_z_sorted = domain_z_sorted.squeeze()\n",
    "        domain_z_sorted = domain_z_sorted[:5]\n",
    "        domain_z_mins[domain_idx, i, :] = domain_z_sorted\n",
    "        # find the top_k largest values of dimension i in domain_z\n",
    "        domain_z_sorted, _ = torch.sort(domain_z[:, i], dim=0, descending=True)\n",
    "        domain_z_sorted = domain_z_sorted.squeeze()\n",
    "        domain_z_sorted = domain_z_sorted[:5]\n",
    "        domain_z_maxs[domain_idx, i, :] = domain_z_sorted\n",
    "\n",
    "mse_mins = F.mse_loss(domain_z_mins[0], domain_z_mins[1], reduction=\"mean\")\n",
    "mse_maxs = F.mse_loss(domain_z_maxs[0], domain_z_maxs[1], reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4542, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# print(domain_z_mins[0])\n",
    "# print(domain_z_mins[1])\n",
    "# print(domain_z_maxs[0])\n",
    "# print(domain_z_maxs[1])\n",
    "mse_mins = F.mse_loss(domain_z_mins[0], domain_z_mins[1], reduction=\"sum\")\n",
    "print(mse_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a function to clamps the values of a numpy array between 0,1\n",
    "def clamp(x):\n",
    "    return np.minimum(np.maximum(x, 0), 1)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    plt.imshow(clamp(recons[i].detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = iter(datamodule.train_dataloader())\n",
    "iterator = iter(datamodule.test_dataloader())\n",
    "# iterator = iter(datamodule.val_dataloader())\n",
    "print(next(iterator)[\"image\"].shape)\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(20,40):\n",
    "    sample = next(iterator)\n",
    "    sample_img, sample_label, sample_domain, sample_color = sample[\"image\"][i], sample[\"label\"][i], sample[\"domain\"][i], sample[\"color\"][i]\n",
    "    print(f\"sample_label: {sample_label}, sample_domain: {sample_domain}, sample_color: {sample_color}\")\n",
    "    plt.figure()\n",
    "    plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(next(iterator)[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.valid_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(datamodule.valid_dataset[0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = data[0][0].permute(1,2,0).repeat(1, 1, 3)\n",
    "test_sample\n",
    "non_bg_pixels = test_sample[:, :, 0] > 0.0\n",
    "# test_sample[non_bg_pixels, :] = test_sample[non_bg_pixels, :] * torch.tensor([1.0, 0.0, 0.0])\n",
    "# test_sample[non_bg_pixels, :] = test_sample[non_bg_pixels, :] * torch.tensor([0.0, 1.0, 0.0])\n",
    "test_sample[non_bg_pixels, :] = test_sample[non_bg_pixels, :] * torch.tensor([0.0, 0.0, 1.0])\n",
    "test_sample[~non_bg_pixels, :] = torch.tensor([0.0, 0.0, 0.0])\n",
    "plt.imshow(test_sample)\n",
    "# should normalize again to be between -1,1 or -0.5 and 0.5\n",
    "# plt.matshow(data[0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for all properties\n",
    "\n",
    "import hydra\n",
    "from slot_based_disentanglement.utils import hydra_custom_resolvers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "from itertools import product\n",
    "import scipy\n",
    "configs_path = \"configs\"\n",
    "# config_name = \"config.yaml\"\n",
    "config_name = \"evaluate_root.yaml\" # \"dummy.yaml\" # \"evaluate_root.yaml\"\n",
    "# config_name = \"train_root.yaml\" # \"dummy.yaml\" # \"evaluate_root.yaml\"\n",
    "from slot_based_disentanglement.utils.lp_solver import lp_solver_cvxpy, lp_solver_pulp\n",
    "\n",
    "\n",
    "n_balls = 4\n",
    "from slot_based_disentanglement.utils import hydra_custom_resolvers\n",
    "with hydra.initialize(config_path=configs_path):\n",
    "    config = hydra.compose(config_name=config_name,\n",
    "                            overrides=[\n",
    "                                # \"model=inertia_balls_saae_contrastive_recons\",\n",
    "                                # \"model.encoder.slot_size=64\",\n",
    "                                # f\"model.encoder.num_slots={n_balls+1}\",\n",
    "                                # \"model.z_dim=2\",\n",
    "                                # \"model.pl_model_ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/slot_attention_inertia_balls_autoencoder_2_cyclic_fixed-epoch\\=1796-train_loss\\=0.00-Linear_Disentanglement\\=0.00-Permutation_Disentanglement\\=0.00.ckpt\",\n",
    "                                # \"ckpt_path=null\",\n",
    "                                # \"datamodule=inertia_balls\",\n",
    "                                # \"datamodule/dataset=all_properties_sparse_offset\",\n",
    "                                # \"datamodule.dataset.signed=False\",\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_3_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1-epoch\\=394-train_loss\\=0.18-Linear_Disentanglement\\=0.37-Permutation_Disentanglement\\=0.47.ckpt\",\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_4_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1-epoch\\=174-train_loss\\=0.33-Linear_Disentanglement\\=0.01-Permutation_Disentanglement\\=0.04.ckpt\",\n",
    "                                # z_dim=4, z_dis=4\n",
    "                                # \"model.signed_change=False\",\n",
    "                                # \"model.z_dim=4\",\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_4_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1-epoch\\=399-train_loss\\=0.15-Linear_Disentanglement\\=0.21-Permutation_Disentanglement\\=0.27.ckpt\"\n",
    "                                \n",
    "                                # z_dim=2, z_dis=2, load from ckpt\n",
    "                                \"model=inertia_balls_saae_contrastive_recons_ckpt\",\n",
    "                                f\"model.num_slots={n_balls+1}\",\n",
    "                                \"model.z_dim=2\",\n",
    "                                \"+model.encoder_ckpt_path=null\",\n",
    "                                # frozen enc-dec\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_2_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1_z_dis_2-epoch\\=399-train_loss\\=0.00-Linear_Disentanglement\\=0.99-Permutation_Disentanglement\\=0.99.ckpt\",\n",
    "                                # finetuned enc-dec\n",
    "                                \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_2_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1_z_dis_2-epoch\\=399-train_loss\\=0.01-Linear_Disentanglement\\=1.00-Permutation_Disentanglement\\=0.98.ckpt\"\n",
    "\n",
    "                                # z_dim=3, z_dis=3, load from ckpt\n",
    "                                # \"model=inertia_balls_saae_contrastive_recons_ckpt\",\n",
    "                                # f\"model.num_slots={n_balls+1}\",\n",
    "                                # \"model.z_dim=3\",\n",
    "                                # \"+model.encoder_ckpt_path=null\",\n",
    "                                # frozen enc-dec\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_3_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1_z_dis_3-epoch\\=399-train_loss\\=0.97-Linear_Disentanglement\\=0.66-Permutation_Disentanglement\\=0.67.ckpt\",\n",
    "                                # finetuned enc-dec\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_3_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1_z_dis_3-epoch\\=399-train_loss\\=0.84-Linear_Disentanglement\\=0.66-Permutation_Disentanglement\\=0.67.ckpt\",\n",
    "                                \n",
    "                                # z_dim=4, z_dis=4, load from ckpt\n",
    "                                # \"model=inertia_balls_saae_contrastive_recons_ckpt\",\n",
    "                                # f\"model.num_slots={n_balls+1}\",\n",
    "                                # \"model.z_dim=4\",\n",
    "                                # \"+model.encoder_ckpt_path=null\",\n",
    "                                # frozen enc-dec\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_4_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1_z_dis_4-epoch\\=299-train_loss\\=1.31-Linear_Disentanglement\\=0.50-Permutation_Disentanglement\\=0.52.ckpt\",\n",
    "                                # finetuned enc-dec\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_4_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1_z_dis_4-epoch\\=299-train_loss\\=0.34-Linear_Disentanglement\\=0.50-Permutation_Disentanglement\\=0.46.ckpt\",\n",
    "\n",
    "                                # z_dim=3, z_dis=3, load from ckpt, position change + shape change (colour fixed)\n",
    "                                # \"model=inertia_balls_saae_contrastive_recons_ckpt\",\n",
    "                                # f\"model.num_slots={n_balls+1}\",\n",
    "                                # \"model.z_dim=3\",\n",
    "                                # \"+model.encoder_ckpt_path=null\",\n",
    "                                # \"ckpt_path=/home/mila/s/sayed.mansouri-tehrani/mechanism-based-disentanglement/disentanglement_by_mechanisms/SA_inertia_balls_contrastive_recons_zdim_3_n_balls_2_cyclic_fixed_argmin_known_mech_False_sparsity_1_z_dis_3-epoch\\=16-train_loss\\=1.26-Linear_Disentanglement\\=0.66-Permutation_Disentanglement\\=0.66.ckpt\",\n",
    "\n",
    "                            ],\n",
    "                            return_hydra_config=True,\n",
    "    )\n",
    "    \n",
    "    # model = hydra.utils.instantiate(config.model, _recursive_=False)\n",
    "\n",
    "    from torchvision import transforms\n",
    "    transform = transforms.Compose([hydra.utils.instantiate(t) for _, t in config.datamodule.transforms.items()])\n",
    "    def renormalize():\n",
    "        for _, t in config.datamodule.transforms.items():\n",
    "            if \"Standardize\" in t[\"_target_\"]:\n",
    "                \"\"\"Renormalize from [-1, 1] to [0, 1].\"\"\"\n",
    "                return lambda x: x / 2.0 + 0.5\n",
    "            \n",
    "            # TODO: add more options if required\n",
    "\n",
    "device = 'cuda'\n",
    "# model.to(device)\n",
    "renormalize = renormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_balls = 3\n",
    "z = np.zeros((n_balls, 6))\n",
    "z[0, :2] = [0.5, 0.25]\n",
    "z[1, :2] = [0., 0.4]\n",
    "z[2, :2] = [0.25, 0.25]\n",
    "# colour\n",
    "z[0, 2] = 0\n",
    "z[1, 2] = 1\n",
    "z[2, 2] = 2\n",
    "# shape\n",
    "z[0, 3] = 0\n",
    "z[1, 3] = 1\n",
    "z[2, 3] = 2\n",
    "# size\n",
    "z[0, 4] = 0.1\n",
    "z[1, 4] = 0.07\n",
    "z[2, 4] = 0.1\n",
    "# rotation angle\n",
    "z[0, 5] = 0.0 # 0.2\n",
    "z[1, 5] = -0.0 # 0.4\n",
    "z[2, 5] = 0.0 # 0.4\n",
    "\n",
    "hsv_colours = [COLOURS_[z[i,2].astype(int)] for i in range(z.shape[0])]\n",
    "rgb_colours = [[255.*channel for channel in colorsys.hls_to_rgb(*c)] for c in hsv_colours]\n",
    "x, seg_mask = draw_scene(z, rgb_colours)\n",
    "x = transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(renormalize(x.permute(1,2,0)))\n",
    "plt.figure()\n",
    "plt.imshow(seg_mask[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for all properties\n",
    "\n",
    "import hydra\n",
    "from slot_based_disentanglement.utils import hydra_custom_resolvers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "from itertools import product\n",
    "import scipy\n",
    "configs_path = \"configs\"\n",
    "# config_name = \"config.yaml\"\n",
    "config_name = \"evaluate_root.yaml\" # \"dummy.yaml\" # \"evaluate_root.yaml\"\n",
    "# config_name = \"train_root.yaml\" # \"dummy.yaml\" # \"evaluate_root.yaml\"\n",
    "from slot_based_disentanglement.utils.lp_solver import lp_solver_cvxpy, lp_solver_pulp\n",
    "\n",
    "\n",
    "n_balls = 4\n",
    "from slot_based_disentanglement.utils import hydra_custom_resolvers\n",
    "with hydra.initialize(config_path=configs_path):\n",
    "    config = hydra.compose(config_name=config_name,\n",
    "                            overrides=[\n",
    "                                \"datamodule=inertia_balls\",\n",
    "                                f\"datamodule.n_balls={n_balls}\",\n",
    "                                f\"datamodule.num_samples.train={10}\",\n",
    "                                f\"datamodule.num_samples.valid={10}\",\n",
    "                                f\"datamodule.num_samples.test={10}\",\n",
    "                                \"datamodule/dataset=all_p_sparse_offset\",\n",
    "                                \"datamodule.dataset.signed=True\",\n",
    "                                \"datamodule.dataset.properties_list=['x','y','c','l','p']\",\n",
    "                                \"datamodule.dataset.z_dim=5\",\n",
    "                            ],\n",
    "                            return_hydra_config=True,\n",
    "    )\n",
    "    \n",
    "    datamodule = hydra.utils.instantiate(config.datamodule, _recursive_=False)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    from torchvision import transforms\n",
    "    transform = transforms.Compose([hydra.utils.instantiate(t) for _, t in config.datamodule.transforms.items()])\n",
    "    def renormalize():\n",
    "        for _, t in config.datamodule.transforms.items():\n",
    "            if \"Standardize\" in t[\"_target_\"]:\n",
    "                \"\"\"Renormalize from [-1, 1] to [0, 1].\"\"\"\n",
    "                return lambda x: x / 2.0 + 0.5\n",
    "            \n",
    "            # TODO: add more options if required\n",
    "\n",
    "renormalize = datamodule.renormalize()\n",
    "iterator = iter(datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1,z2 = batch[\"latents\"]\n",
    "x1,x2 = batch[\"images\"]\n",
    "s1,s2 = batch[\"segmentation_masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x2.min())\n",
    "print(x2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(x1[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "for i in range(n):\n",
    "    plt.figure()\n",
    "    plt.imshow(x1[i].permute(1,2,0))\n",
    "    plt.figure()\n",
    "    plt.imshow(x2[i].permute(1,2,0))\n",
    "# for i in range(0,1):\n",
    "#     for j in range(4):\n",
    "#         plt.figure()\n",
    "#         plt.imshow(s1[i][j])\n",
    "#         plt.figure()\n",
    "#         plt.imshow(s2[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    plt.figure()\n",
    "    plt.imshow(renormalize(x1[i].permute(1,2,0)))\n",
    "    plt.figure()\n",
    "    plt.imshow(renormalize(x2[i].permute(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "print(z1[:num_samples, :2])\n",
    "print(z1[:num_samples, 6:8])\n",
    "print(f\"--------------------======--------------------\")\n",
    "print(z2[:num_samples, :2])\n",
    "print(z2[:num_samples, 6:8])\n",
    "print(f\"--------------------======--------------------\")\n",
    "print((z2[:num_samples]-z1[:num_samples]).reshape(num_samples, n_balls, -1))\n",
    "print((np.linalg.norm(z2[:num_samples, :2]-z1[:num_samples, :2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.linalg.norm(z1.reshape(z1.shape[0], -1, 6)[:num_samples, 0, :2]-z1.reshape(z1.shape[0], -1, 6)[:num_samples, 1, :2], ord=2, axis=1)\n",
    "print(dists)\n",
    "print(z1[:num_samples, 4] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import os\n",
    "from pygame import gfxdraw\n",
    "import colorsys\n",
    "import math\n",
    "\n",
    "\n",
    "if \"SDL_VIDEODRIVER\" not in os.environ:\n",
    "    os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "    os.environ[\"SDL_AUDIODRIVER\"] = \"dsp\"\n",
    "\n",
    "# HSV colours\n",
    "COLOURS_ = [\n",
    "    [0.05, 0.6, 0.6],\n",
    "    # [0.15, 0.6, 0.6],\n",
    "    [0.25, 0.6, 0.6],\n",
    "    # [0.35, 0.6, 0.6],\n",
    "    [0.45, 0.6, 0.6],\n",
    "    # [0.55, 0.6, 0.6],\n",
    "    [0.65, 0.6, 0.6],\n",
    "    # [0.75, 0.6, 0.6],\n",
    "    [0.85, 0.6, 0.6],\n",
    "    # [0.95, 0.6, 0.6],\n",
    "]\n",
    "\n",
    "SHAPES_ = [\n",
    "    \"circle\",\n",
    "    \"square\",\n",
    "    \"triangle\",\n",
    "    \"heart\"\n",
    "]\n",
    "\n",
    "SCREEN_DIM = 128\n",
    "Y_SHIFT = 0.0\n",
    "\n",
    "def draw_shape(\n",
    "    x_,\n",
    "    y_,\n",
    "    surf,\n",
    "    color=(204, 204, 0),\n",
    "    radius=0.1,\n",
    "    screen_width=SCREEN_DIM,\n",
    "    y_shift=Y_SHIFT,\n",
    "    offset=None,\n",
    "    shape=\"circle\",\n",
    "    rotation_angle=0.\n",
    "):\n",
    "    if offset is None:\n",
    "        offset = screen_width / 2\n",
    "    scale = screen_width\n",
    "    x = scale * x_ + offset\n",
    "    y = scale * y_ + offset\n",
    "\n",
    "    temp_surf = pygame.Surface((screen_width, screen_width), pygame.SRCALPHA)\n",
    "    # temp_surf_rotation = pygame.Surface((screen_width, screen_width), pygame.SRCALPHA) # for rotations\n",
    "    temp_surf_rotation = pygame.Surface((20, 20), pygame.SRCALPHA) # for rotations\n",
    "\n",
    "    if shape == \"circle\":\n",
    "        # pygame.draw.circle(surface=surf, color=color,\n",
    "        #                center=(int(x), int(y - offset * y_shift)), radius=int(radius * scale))\n",
    "        gfxdraw.aacircle(\n",
    "            temp_surf_rotation, 0, 0, int(radius * scale), color\n",
    "            )\n",
    "        gfxdraw.filled_circle(\n",
    "            temp_surf_rotation, 0, 0, int(radius * scale), color\n",
    "        )\n",
    "\n",
    "        # for segmentation mask\n",
    "        gfxdraw.aacircle(\n",
    "        temp_surf, 0, 0, int(radius * scale), color\n",
    "            )\n",
    "        gfxdraw.filled_circle(\n",
    "            temp_surf, 0, 0, int(radius * scale), color\n",
    "            )\n",
    "\n",
    "    elif shape == \"square\":\n",
    "        radius = int(radius * scale)*2\n",
    "        pygame.draw.polygon(surface=temp_surf_rotation, color=color,\n",
    "                        points=[(int(i), int(j)) for i, j in [(0,0), (radius,0), (radius,radius), (0,radius)]])\n",
    "        # for segmentation mask\n",
    "        pygame.draw.polygon(surface=temp_surf, color=color,\n",
    "                        points=[(int(i), int(j)) for i, j in [(0,0), (radius,0), (radius,radius), (0,radius)]])\n",
    "\n",
    "    elif shape == \"triangle\":\n",
    "        radius = (radius * scale)*2\n",
    "        # x, y = ((x) - radius/2, (y - offset * y_shift) - radius/2)\n",
    "        pygame.draw.polygon(surface=temp_surf_rotation, color=color,\n",
    "                        points=[(int(i), int(j)) for i, j in [(radius//2,radius), (radius,0), (0,0)]])\n",
    "        # for segmentation mask\n",
    "        pygame.draw.polygon(surface=temp_surf, color=color,\n",
    "                        points=[(int(i), int(j)) for i, j in [(radius//2,radius), (radius,0), (0,0)]])\n",
    "\n",
    "    elif shape == \"heart\":\n",
    "        radius = (radius * scale)*2\n",
    "        s = 3.4 # 3.5\n",
    "        j = 1.33\n",
    "        pygame.draw.circle(surface=temp_surf_rotation, color=color,\n",
    "                    center=(int(3 * radius /(s * j)), int(radius/(s * j) + radius/2)), radius=int(radius/s))\n",
    "        pygame.draw.circle(surface=temp_surf_rotation, color=color,\n",
    "                    center=(int(radius/(s*j)), int(radius /(s*j) + radius/2)), radius=int(radius/s))\n",
    "        pygame.draw.polygon(surface=temp_surf_rotation, color=color,\n",
    "                        points=[(int(np.floor(i)), int(np.floor(j))) for i, j in [(2*radius/(s*j),0), (2 * radius/(s*j) - radius/2.0,radius/30 + radius/2), (2*radius/(s*j) + radius/2.0,radius/30 + radius/2)]])\n",
    "        # for segmentation mask\n",
    "        pygame.draw.circle(surface=temp_surf, color=color,\n",
    "                    center=(int(3 * radius /(s * j)), int(radius/(s * j) + radius/2)), radius=int(radius/s))\n",
    "        pygame.draw.circle(surface=temp_surf, color=color,\n",
    "                    center=(int(radius/(s*j)), int(radius /(s*j) + radius/2)), radius=int(radius/s))\n",
    "        pygame.draw.polygon(surface=temp_surf, color=color,\n",
    "                        points=[(int(np.floor(i)), int(np.floor(j))) for i, j in [(2*radius/(s*j),0), (2 * radius/(s*j) - radius/2.0,radius/30 + radius/2), (2*radius/(s*j) + radius/2.0,radius/30 + radius/2)]])\n",
    "\n",
    "    rotated_surf = pygame.Surface((screen_width, screen_width), pygame.SRCALPHA)\n",
    "    # Rotate the temporary surface with the rectangle and blit it onto the new surface\n",
    "    # rotated_surf.blit(pygame.transform.rotate(temp_surf_rotation, math.degrees(rotation_angle)), (0, 0))\n",
    "\n",
    "    rotated_surf_rect = temp_surf_rotation.get_rect(center=(int(x), int(y)))\n",
    "    \n",
    "    rotated_fuck = pygame.transform.rotate(temp_surf_rotation, math.degrees(rotation_angle))\n",
    "    rotated_surf_rect = rotated_fuck.get_rect(center=(int(x), int(y)))\n",
    "    \n",
    "    rotated_surf.blit(pygame.transform.rotate(temp_surf_rotation, math.degrees(rotation_angle)), rotated_surf_rect)\n",
    "    surf.blit(rotated_surf, (0, 0))\n",
    "    # rotated_surf.blit(pygame.transform.rotate(temp_surf_rotation, math.degrees(rotation_angle)), (int(x), int(y)))\n",
    "    # surf.blit(rotated_surf, (int(x), int(y)))\n",
    "\n",
    "    temp_surf_pos = (0,0)\n",
    "    ball_mask = pygame.mask.from_surface(temp_surf)\n",
    "\n",
    "    # mask -› surface\n",
    "    new_temp_surf = ball_mask.to_surface()\n",
    "    # do the same flip as the one occurring for the screen\n",
    "    new_temp_surf = pygame.transform.flip(new_temp_surf, False, True)\n",
    "    new_temp_surf.set_colorkey((0,0,0))\n",
    "\n",
    "    return np.transpose(np.array(pygame.surfarray.pixels3d(new_temp_surf)), axes=(1, 0, 2))[:, :, :1] # [screen_width, screen_width, 1]\n",
    "    \n",
    "    # temp_surf_pos = (0,0)\n",
    "    # ball_mask = pygame.mask.from_surface(temp_surf)\n",
    "\n",
    "    # # mask -› surface\n",
    "    # new_temp_surf = ball_mask.to_surface()\n",
    "    # # do the same flip as the one occurring for the screen\n",
    "    # new_temp_surf = pygame.transform.flip(new_temp_surf, False, True)\n",
    "    # new_temp_surf.set_colorkey((0,0,0))\n",
    "\n",
    "    # return np.transpose(np.array(pygame.surfarray.pixels3d(new_temp_surf)), axes=(1, 0, 2))[:, :, :1] # [screen_width, screen_width, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "screen_dim = 128\n",
    "ball_rad = 0.08\n",
    "screen = pygame.display.set_mode((screen_dim, screen_dim))\n",
    "surf = pygame.Surface((screen_dim, screen_dim))\n",
    "\n",
    "def draw_scene(z, colours=None, human_mode=True):\n",
    "    global surf\n",
    "    global screen\n",
    "    surf.fill((255, 255, 255))\n",
    "    bg_surf = pygame.Surface((screen_dim, screen_dim), pygame.SRCALPHA)\n",
    "\n",
    "    obj_masks = []\n",
    "    if z.ndim == 1:\n",
    "        z = z.reshape((1, 2))\n",
    "    if colours is None:\n",
    "        colours = [COLOURS_[3]] * z.shape[0]\n",
    "    for i in range(z.shape[0]):\n",
    "        obj_masks.append(\n",
    "            draw_shape(\n",
    "                z[i, 0],\n",
    "                z[i, 1],\n",
    "                surf,\n",
    "                color=colours[i],\n",
    "                radius=z[i,4],\n",
    "                screen_width=screen_dim,\n",
    "                y_shift=0.0,\n",
    "                offset=0.0,\n",
    "                shape=SHAPES_[int(z[i,3])],\n",
    "                rotation_angle=z[i,5]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        _ = draw_shape(\n",
    "                z[i, 0],\n",
    "                z[i, 1],\n",
    "                bg_surf,\n",
    "                color=colours[i],\n",
    "                radius=z[i,4],\n",
    "                screen_width=screen_dim,\n",
    "                y_shift=0.0,\n",
    "                offset=0.0,\n",
    "                shape=SHAPES_[int(z[i,3])],\n",
    "                rotation_angle=z[i,5]\n",
    "            )\n",
    "\n",
    "        bg_surf_pos = (0,0)\n",
    "        bg_mask = pygame.mask.from_surface(bg_surf)\n",
    "        bg_mask.invert() # so that mask bits for balls are cleared and the bg gets set.\n",
    "\n",
    "        # mask -› surface\n",
    "        new_bg_surf = bg_mask.to_surface()\n",
    "        new_bg_surf.set_colorkey((0,0,0))\n",
    "        # do the same flip as the one occurring for the screen\n",
    "        new_bg_surf = pygame.transform.flip(new_bg_surf, False, True)\n",
    "\n",
    "        # print(np.array(pygame.surfarray.pixels3d(new_bg_surf)).shape)\n",
    "        # bg_mask = np.array(pygame.surfarray.pixels3d(new_bg_surf))[:, :, :1] # [screen_width, screen_width, 1]\n",
    "        bg_mask = np.transpose(np.array(pygame.surfarray.pixels3d(new_bg_surf)), axes=(1, 0, 2))[:, :, :1] # [screen_width, screen_width, 1]\n",
    "    # ------------------------------------------ #\n",
    "    surf = pygame.transform.flip(surf, False, True)\n",
    "    screen.blit(surf, (0, 0))\n",
    "    if human_mode:\n",
    "        pygame.display.flip()\n",
    "    return (\n",
    "        np.transpose(\n",
    "            np.array(pygame.surfarray.pixels3d(screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "        , np.array([bg_mask] + obj_masks)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_balls = 2\n",
    "z = np.zeros((n_balls, 6))\n",
    "for i in range(n_balls):\n",
    "    z[i, :2] = [0.5, 0.5]\n",
    "    # colour\n",
    "    z[i, 2] = i % 5\n",
    "    # shape\n",
    "    z[i, 3] = 3\n",
    "    # size\n",
    "    z[i, 4] = 0.16\n",
    "    # rotation angle\n",
    "    z[i, 5] = 0.4*i # 0.2\n",
    "\n",
    "\n",
    "hsv_colours = [COLOURS_[z[i,2].astype(int)] for i in range(z.shape[0])]\n",
    "rgb_colours = [[255.*channel for channel in colorsys.hls_to_rgb(*c)] for c in hsv_colours]\n",
    "x, seg_mask = draw_scene(z, rgb_colours)\n",
    "x = transform(x)\n",
    "img = renormalize(x.permute(1,2,0))\n",
    "img[int(128*0.5)-2:int(128*0.5)+2, int(128*0.5)-2:int(128*0.5)+2, :] = 0.8\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# data = torch.load(\"/home/mila/s/sayed.mansouri-tehrani/train_dataset_xy_2000.pt\")\n",
    "data = torch.load(\"/home/mila/s/sayed.mansouri-tehrani/test_dataset_xy_100.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2 = data[0][\"images\"]\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x2.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Autoencoder with ResNet18 Encoder\n",
    "class ResNet18Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18Autoencoder, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet18\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        # Modify the last fully connected layer to output 64 features\n",
    "        resnet18.fc = nn.Linear(512, 64)\n",
    "        self.encoder = resnet18 # nn.Sequential(*list(resnet18.children())[:-2])  # Exclude the last two layers\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 4, kernel_size=2, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 3, kernel_size=4, stride=2, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # # nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            # # nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(32, 16, kernel_size=2, stride=1, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(8, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()  # Output range [0, 1] for images\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded.view(encoded.size(0), 64, 1, 1))\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = ResNet18Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 28, 28])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o(img.permute(0,3,1,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
