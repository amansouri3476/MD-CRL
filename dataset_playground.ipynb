{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Mixing Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sayed.mansouri-tehrani/.conda/envs/bb/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "# use hydra configs to load the dataset\n",
    "import hydra\n",
    "from utils import hydra_custom_resolvers\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "configs_path = \"configs\"\n",
    "# config_name = \"train_root.yaml\"\n",
    "config_name = \"train_root.yaml\"\n",
    "\n",
    "with hydra.initialize(config_path=configs_path):\n",
    "    config = hydra.compose(config_name=config_name,\n",
    "                            overrides=[\n",
    "                                \"datamodule=mixing\",\n",
    "                                \"datamodule.dataset.num_domains=10\",\n",
    "                                # \"model=mixing\"\n",
    "                            ],\n",
    "                            return_hydra_config=True,\n",
    "    )\n",
    "\n",
    "    # setup the dataset with the hydra config\n",
    "    datamodule = hydra.utils.instantiate(config.datamodule, _recursive_=False)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    # instantiate the model with hydra\n",
    "    # model = hydra.utils.instantiate(config.model, _recursive_=False)\n",
    "\n",
    "iterator = iter(datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim_invariant_data = datamodule.train_dataset.dataset.z_dim_invariant\n",
    "z_dim = datamodule.train_dataset.dataset.z_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0984)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"z\"][(batch[\"domain\"] == 1).squeeze(), :z_dim_invariant_data].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "domain:0, z_dim:2 -- min:-3.395689010620117, max:-1.9791346788406372, mean:-2.710878849029541\n",
      "domain:0, z_dim:3 -- min:-1.2148573398590088, max:-0.8057138919830322, mean:-1.0142569541931152\n",
      "domain:1, z_dim:2 -- min:-4.767006874084473, max:-2.539933681488037, mean:-3.676292896270752\n",
      "domain:1, z_dim:3 -- min:-4.0764007568359375, max:-0.9848365783691406, mean:-2.4427056312561035\n",
      "domain:2, z_dim:2 -- min:-1.7045924663543701, max:-0.3207516670227051, mean:-0.9372190237045288\n",
      "domain:2, z_dim:3 -- min:1.9994860887527466, max:2.109677791595459, mean:2.0614607334136963\n",
      "domain:3, z_dim:2 -- min:3.3331382274627686, max:4.46589469909668, mean:3.8830065727233887\n",
      "domain:3, z_dim:3 -- min:-2.0340495109558105, max:-0.48385369777679443, mean:-1.1251734495162964\n",
      "domain:4, z_dim:2 -- min:-2.998680353164673, max:-1.8430469036102295, mean:-2.490309715270996\n",
      "domain:4, z_dim:3 -- min:-4.002238750457764, max:-3.2039177417755127, mean:-3.526283025741577\n",
      "domain:5, z_dim:2 -- min:-4.054628849029541, max:-0.6411967277526855, mean:-2.3517112731933594\n",
      "domain:5, z_dim:3 -- min:3.238177537918091, max:4.8626790046691895, mean:4.02437162399292\n",
      "domain:6, z_dim:2 -- min:3.003408670425415, max:3.540334701538086, mean:3.2923946380615234\n",
      "domain:6, z_dim:3 -- min:-2.2823867797851562, max:-1.5723302364349365, mean:-1.9512783288955688\n",
      "domain:7, z_dim:2 -- min:2.2318673133850098, max:3.1999824047088623, mean:2.687049627304077\n",
      "domain:7, z_dim:3 -- min:1.573473334312439, max:2.007068395614624, mean:1.7897320985794067\n",
      "domain:8, z_dim:2 -- min:1.8634604215621948, max:2.204680919647217, mean:2.049686908721924\n",
      "domain:8, z_dim:3 -- min:-3.5353214740753174, max:-0.9030609130859375, mean:-2.120600938796997\n",
      "domain:9, z_dim:2 -- min:-4.245664596557617, max:-1.352147102355957, mean:-2.533360242843628\n",
      "domain:9, z_dim:3 -- min:-2.720309257507324, max:-2.100924253463745, mean:-2.4299817085266113\n"
     ]
    }
   ],
   "source": [
    "for domain_idx in range(datamodule.train_dataset.dataset.num_domains):\n",
    "    print(f\"domain:{domain_idx} -- min:{batch['z'][(batch['domain'] == domain_idx).squeeze(), :z_dim_invariant_data].min()}, max:{batch['z'][(batch['domain'] == domain_idx).squeeze(), :z_dim_invariant_data].max()}, mean:{batch['z'][(batch['domain'] == domain_idx).squeeze(), :z_dim_invariant_data].mean()}\")\n",
    "print(\"----------------\")\n",
    "for domain_idx in range(datamodule.train_dataset.dataset.num_domains):\n",
    "    print(f\"domain:{domain_idx} -- min:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_invariant_data:].min()}, max:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_invariant_data:].max()}, mean:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_invariant_data:].mean()}\")\n",
    "print(\"----------------\")\n",
    "for domain_idx in range(datamodule.train_dataset.dataset.num_domains):\n",
    "    for z_dim_spurious in range(z_dim_invariant_data, z_dim):\n",
    "        print(f\"domain:{domain_idx}, z_dim:{z_dim_spurious} -- min:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_spurious].min()}, max:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_spurious].max()}, mean:{batch['z'][(batch['domain'] == domain_idx).squeeze(), z_dim_spurious].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coloured MNIST Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golden standard\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "# laod MNIST\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "root = \"/network/datasets/torchvision\"\n",
    "data = torchvision.datasets.MNIST(root, True, transform=transform)\n",
    "\n",
    "# color it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].permute(1,2,0).repeat(1, 1, 3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sayed.mansouri-tehrani/.conda/envs/bb/lib/python3.7/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "# use hydra configs to load the dataset\n",
    "import hydra\n",
    "from utils import hydra_custom_resolvers\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "configs_path = \"configs\"\n",
    "# config_name = \"train_root.yaml\"\n",
    "config_name = \"evaluate_root.yaml\"\n",
    "\n",
    "with hydra.initialize(config_path=configs_path):\n",
    "    config = hydra.compose(config_name=config_name,\n",
    "                            overrides=[\n",
    "                                # \"datamodule/dataset=mnist\",\n",
    "                                \"datamodule/dataset=multi_domain_mnist\",\n",
    "                                # \"+ckpt_path='/home/mila/s/sayed.mansouri-tehrani/MD-CRL/autoencoder_multi_domain_mnist_32-epoch=52-val_loss=0.01.ckpt'\",\n",
    "                                # \"model.autoencoder.num_channels=3\",\n",
    "                            ],\n",
    "                            return_hydra_config=True,\n",
    "    )\n",
    "\n",
    "    transform = transforms.Compose([hydra.utils.instantiate(t) for _, t in config.datamodule.transforms.items()])\n",
    "    def renormalize():\n",
    "        for _, t in config.datamodule.transforms.items():\n",
    "            if \"Standardize\" in t[\"_target_\"]:\n",
    "                \"\"\"Renormalize from [-1, 1] to [0, 1].\"\"\"\n",
    "                return lambda x: x / 2.0 + 0.5\n",
    "            \n",
    "    # setup the dataset with the hydra config\n",
    "    datamodule = hydra.utils.instantiate(config.datamodule, _recursive_=False)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    # instantiate the model with hydra\n",
    "    # model = hydra.utils.instantiate(config.model, _recursive_=False)\n",
    "\n",
    "renormalize = datamodule.renormalize()\n",
    "iterator = iter(datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hydra configs to load the dataset\n",
    "import hydra\n",
    "from utils import hydra_custom_resolvers\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Image, ImageEnhance\n",
    "configs_path = \"configs\"\n",
    "config_name = \"train_root.yaml\"\n",
    "# config_name = \"evaluate_root.yaml\"\n",
    "\n",
    "with hydra.initialize(config_path=configs_path):\n",
    "    config = hydra.compose(config_name=config_name,\n",
    "                            overrides=[\n",
    "                                # \"datamodule/dataset=mnist\",\n",
    "                                # \"datamodule/dataset=multi_domain_mnist\",\n",
    "                                # \"+ckpt_path='/home/mila/s/sayed.mansouri-tehrani/MD-CRL/autoencoder_multi_domain_mnist_32-epoch=52-val_loss=0.01.ckpt'\",\n",
    "                                \"model.autoencoder.num_channels=3\",\n",
    "                                # \"model.autoencoder.num_channels=3\",\n",
    "                            ],\n",
    "                            return_hydra_config=True,\n",
    "    )\n",
    "\n",
    "    # instantiate the model with hydra\n",
    "    model = hydra.utils.instantiate(config.model, _recursive_=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load(\"/home/mila/s/sayed.mansouri-tehrani/MD-CRL/autoencoder_multi_domain_mnist_32-epoch=52-val_loss=0.01.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in model.state_dict().keys():\n",
    "    print((model.state_dict()[key] == m[\"state_dict\"][key].to('cpu')).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"decoder_fc\":   {'_target_': 'models.modules.fc_ae.Decoder', 'latent_size': 32, 'width': 28, 'height': 28, 'num_channels': 3, 'decoder_layers': {'Linear1': {'_target_': 'torch.nn.Linear', 'in_features': 32, 'out_features': 64}, 'LeakyReLU1': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout1': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear2': {'_target_': 'torch.nn.Linear', 'in_features': 64, 'out_features': 128}, 'LeakyReLU2': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout2': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear3': {'_target_': 'torch.nn.Linear', 'in_features': 128, 'out_features': 256}, 'LeakyReLU3': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout3': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear4': {'_target_': 'torch.nn.Linear', 'in_features': 256, 'out_features': 512}, 'LeakyReLU4': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout4': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear5': {'_target_': 'torch.nn.Linear', 'in_features': 512, 'out_features': 2352}, 'LeakyReLU5': {'_target_': 'torch.nn.LeakyReLU'}}}\n",
       "\"encoder_fc\":   {'_target_': 'models.modules.fc_ae.Encoder', 'latent_size': 32, 'width': 28, 'height': 28, 'encoder_layers': {'Flatten': {'_target_': 'torch.nn.Flatten'}, 'Linear1': {'_target_': 'torch.nn.Linear', 'in_features': 2352, 'out_features': 512}, 'LeakyReLU1': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout1': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear2': {'_target_': 'torch.nn.Linear', 'in_features': 512, 'out_features': 256}, 'LeakyReLU2': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout2': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear3': {'_target_': 'torch.nn.Linear', 'in_features': 256, 'out_features': 128}, 'LeakyReLU3': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout3': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear4': {'_target_': 'torch.nn.Linear', 'in_features': 128, 'out_features': 64}, 'LeakyReLU4': {'_target_': 'torch.nn.LeakyReLU'}, 'Dropout4': {'_target_': 'torch.nn.Dropout', 'p': 0.5}, 'Linear5': {'_target_': 'torch.nn.Linear', 'in_features': 64, 'out_features': 32}, 'LeakyReLU5': {'_target_': 'torch.nn.LeakyReLU'}}}\n",
       "\"height\":       28\n",
       "\"latent_dim\":   32\n",
       "\"num_channels\": 3\n",
       "\"width\":        28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator)\n",
    "img, labels = batch[\"image\"], batch[\"label\"]\n",
    "# img, labels, domains, colors = batch[\"image\"], batch[\"label\"], batch[\"domain\"], batch[\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 3 images from each domain\n",
    "fig, axs = plt.subplots(datamodule.train_dataset.dataset.num_domains, 3, figsize=(10, 10))\n",
    "for domain_idx in range(datamodule.train_dataset.dataset.num_domains):\n",
    "    for img_idx in range(3):\n",
    "        axs[domain_idx, img_idx].imshow(img[(labels == img_idx) & (batch[\"domain\"] == domain_idx)][0].permute(1,2,0))\n",
    "        axs[domain_idx, img_idx].set_title(f\"domain:{domain_idx}, label:{img_idx}\")\n",
    "        axs[domain_idx, img_idx].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, recons = model.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_z_mins = torch.zeros((2, 16, 5))\n",
    "domain_z_maxs = torch.zeros((2, 16, 5))\n",
    "\n",
    "# z is [batch_size, latent_dim], so is domains. For the first d dimensions\n",
    "# of z, find the top_k smallest values of that dimension in each domain\n",
    "# find the mask of z's for each domain\n",
    "# for each domain, and for each of the first d dimensions, \n",
    "# find the top_k smallest values of that z dimension in that domain\n",
    "for domain_idx in range(2):\n",
    "    domain_mask = (domains == domain_idx).squeeze()\n",
    "    domain_z = z[domain_mask]\n",
    "    # for each dimension i among the first d dimensions of z, find the top_k\n",
    "    # smallest values of dimension i in domain_z\n",
    "    for i in range(16):\n",
    "        domain_z_sorted, _ = torch.sort(domain_z[:, i], dim=0)\n",
    "        domain_z_sorted = domain_z_sorted.squeeze()\n",
    "        domain_z_sorted = domain_z_sorted[:5]\n",
    "        domain_z_mins[domain_idx, i, :] = domain_z_sorted\n",
    "        # find the top_k largest values of dimension i in domain_z\n",
    "        domain_z_sorted, _ = torch.sort(domain_z[:, i], dim=0, descending=True)\n",
    "        domain_z_sorted = domain_z_sorted.squeeze()\n",
    "        domain_z_sorted = domain_z_sorted[:5]\n",
    "        domain_z_maxs[domain_idx, i, :] = domain_z_sorted\n",
    "\n",
    "mse_mins = F.mse_loss(domain_z_mins[0], domain_z_mins[1], reduction=\"mean\")\n",
    "mse_maxs = F.mse_loss(domain_z_maxs[0], domain_z_maxs[1], reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4542, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# print(domain_z_mins[0])\n",
    "# print(domain_z_mins[1])\n",
    "# print(domain_z_maxs[0])\n",
    "# print(domain_z_maxs[1])\n",
    "mse_mins = F.mse_loss(domain_z_mins[0], domain_z_mins[1], reduction=\"sum\")\n",
    "print(mse_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a function to clamps the values of a numpy array between 0,1\n",
    "def clamp(x):\n",
    "    return np.minimum(np.maximum(x, 0), 1)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    plt.imshow(clamp(recons[i].detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = iter(datamodule.train_dataloader())\n",
    "iterator = iter(datamodule.test_dataloader())\n",
    "# iterator = iter(datamodule.val_dataloader())\n",
    "print(next(iterator)[\"image\"].shape)\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(20,40):\n",
    "    sample = next(iterator)\n",
    "    sample_img, sample_label, sample_domain, sample_color = sample[\"image\"][i], sample[\"label\"][i], sample[\"domain\"][i], sample[\"color\"][i]\n",
    "    print(f\"sample_label: {sample_label}, sample_domain: {sample_domain}, sample_color: {sample_color}\")\n",
    "    plt.figure()\n",
    "    plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderPL(\n",
       "  (model): CNNAE(\n",
       "    (encoder_cnn): Encoder(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(3, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (7): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (decoder_cnn): Decoder(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): ConvTranspose2d(16, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU()\n",
       "        (9): ConvTranspose2d(8, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (11): ReLU()\n",
       "        (12): ConvTranspose2d(4, 4, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
       "        (13): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (14): ReLU()\n",
       "        (15): ConvTranspose2d(4, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (16): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
