_target_: models.modules.fc_ae_synthetic.FCAE

activation: torch.nn.ReLU # torch.nn.ReLU, torch.nn.LeakyReLU, torch.nn.Sigmoid, torch.nn.Tanh
latent_dim: ${model.z_dim_invariant}

encoder_fc:
  _target_: models.modules.fc_ae_synthetic.Encoder

  encoder_layers:
    Linear1:
      _target_: torch.nn.Linear
      in_features: ${datamodule.dataset.x_dim}
      out_features: ${floor_div:${datamodule.dataset.x_dim},2}
      bias: True
    # ReLU1:
    #   _target_: torch.nn.ReLU
    ReLU1:
      _target_: ${model.autoencoder.activation} # torch.nn.Tanh
    Linear2:
      _target_: torch.nn.Linear
      in_features: ${floor_div:${datamodule.dataset.x_dim},2}
      out_features: ${model.autoencoder.latent_dim}
      bias: True
    # ReLU2:
    #   _target_: torch.nn.ReLU

    
decoder_fc:
  _target_: models.modules.fc_ae_synthetic.Decoder

  decoder_layers:
    Linear1:
      _target_: torch.nn.Linear
      in_features: ${model.autoencoder.latent_dim}
      out_features: ${mult_int:${model.autoencoder.latent_dim},2}
      bias: True
    # ReLU1:
    #   _target_: torch.nn.ReLU
    ReLU1:
      _target_: ${model.autoencoder.activation} # torch.nn.Tanh
    Linear2:
      _target_: torch.nn.Linear
      in_features: ${mult_int:${model.autoencoder.latent_dim},2}
      out_features: ${datamodule.dataset.x_dim}
      bias: True
    # ReLU2:
    #   _target_: torch.nn.ReLU